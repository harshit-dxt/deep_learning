{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MNIST digits classification task using Dense Network</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading the dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Visualizing the data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[900]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Network architecture</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/harshitdixit/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28, )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>Our network consists of two <i>Dense</i> layers which are densely connected neural layers. The second layer is a 10-way softmax layer, which means it returns an array of 10 probability scores.</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>Each layer in a deep network applies a transformation that disentangles the data a littleâ€”and a deep stack of layers makes tractable an extremely complicated disentanglement process.</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compilation Step</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>We have our model ready but before compiling our model, we need three more things.\n",
    "<ul>\n",
    "<li>Loss Function</li>\n",
    "<li>Optimizer</li>\n",
    "<li>Metrics to monitor during training and testing</li>\n",
    "</ul></blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparing the image data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>Before training, we will preprocess the data by reshaping it into the shape network expects and scaling it so that all values are in the [0, 1] interval.</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparing the labels</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training the network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/harshitdixit/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.2542 - accuracy: 0.9258\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.1022 - accuracy: 0.9702\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0674 - accuracy: 0.9798\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0493 - accuracy: 0.9855\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0383 - accuracy: 0.9880\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0283 - accuracy: 0.9916\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0218 - accuracy: 0.9936\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0171 - accuracy: 0.9949\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0130 - accuracy: 0.9964\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0101 - accuracy: 0.9973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe2f7572e50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Accuracy and Loss of trained model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 68us/step\n",
      "Test Accuracy: 0.9818000197410583\n",
      "Test Loss: 0.06835417314739388\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('Test Accuracy:', test_acc)\n",
    "print('Test Loss:', test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Prediction on the test images</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.predict_classes(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>First test image visualization</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = test_images[0].reshape((28,28))\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Prediction on first image</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.predict_classes(test_images)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
